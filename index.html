<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FKA-Owl: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs.">
  <meta name="keywords" content="Multimodal Fake News Detection, Large Vision-Language Model, Knowledge Augmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FKA-Owl: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs.</title>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css">
  <style>
    .carousel-item img {
      width: 100%;
      height: auto;
      max-height: 800px; /* Adjust the max height as needed */
      object-fit: cover;
    }
    .your-carousel {
      max-width: 920px; /* Adjust the width as needed */
      margin: auto;
    }
  </style>

  <style>
    .carousel-video-item video {
      width: 100%;
      height: auto;
      max-height: 500px; /* Adjust the max height as needed */
      object-fit: cover;
    }
    .your-carousel-video {
      max-width: 800px; /* Adjust the width as needed */
      margin: auto;
    }
  </style>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>


<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FKA-Owl: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs</h1>
          <h1 class="is-size-3"> ACM MM 2024 </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Xuannan Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Peipei Li</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a>Huaibo Huang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a> Zekun Li</a><sup>3</sup>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Xing Cui</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Jiahao Liang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a> Lixiong Qin</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a> Weihong Deng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a> Zhaofeng He</a><sup>1</sup>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Beijing University of Posts and Telecommunications&ensp;</span>
            <span class="author-block"><sup>2</sup>MAIS & NLPR, Institute of Automation, Chinese Academy of Sciences</span>
            <span class="author-block"><sup>3</sup>University of California, Santa Barbara</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.01988"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.01988"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/liuxuannan/FAK-Owl"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--Teaser-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/forgery-knowledge.jpg" alt="Teaser Image" height="100%">
      <h2 class="subtitle has-text-centered">
        (a) An example of a manipulated image-text pair.
        (b) Existing LVLMs struggle to correctly judge the news veracity.
        (c) Incorporating forgery-specific knowledge (i.e., semantic correlation and artifact trace) into LVLM helps the model make accurate predictions.
      </h2>
    </div>
  </div>
</section>


<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">



          <p>
          The massive generation of multimodal fake news involving both text and images exhibits substantial distribution discrepancies, prompting the need for generalized detectors. However, the insulated nature of training restricts the capability of classical detectors to obtain open-world facts.
            While Large Vision-Language Models (LVLMs) have encoded rich world knowledge, they are not inherently tailored for combating fake news and struggle to comprehend local forgery details.
          </p>
          <p>
            In this paper, we propose FKA-Owl, a novel framework that leverages <strong>f</strong>orgery-specific <strong>k</strong>nowledge to <strong>a</strong>ugment LVLMs, enabling them to reason about manipulations effectively.
          </p>
          <p>
          The augmented forgery-specific knowledge includes semantic correlation between text and images, and artifact trace in image manipulation.
            To inject these two kinds of knowledge into the LVLM, we design two specialized modules to establish their representations, respectively. The encoded knowledge embeddings are then incorporated into LVLMs.
          </p>
          <p>
          Extensive experiments on the public benchmark demonstrate that FKA-Owl achieves superior cross-domain performance compared to previous methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<!--/ Abstract. -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <div class="hero-body">
          <img src="./static/images/framework.jpg" alt="Teaser Image" height="100%">
<!--          <h2 class="subtitle has-text-centered">-->
<!--            (a) Stylized image generation with a single reference image.-->
<!--            Our InstaStyle excels at capturing style details including colors, textures, and brush strokes.-->
<!--          </h2>-->
        </div>

        <div class="content has-text-justified">
          <p>
            Our motivation is to leverage rich world knowledge from large vision-language models (LVLMs) and enhancing them with forgery-specific knowledge, to tackle the domain shift issue in multimodal fake news.
          </p>
          <p>
            FKA-Owl consists of an image encoder (ImageBind), a cross-modal reasoning module, a visual-artifact localization module, and a large language model.
            The cross-modal reasoning module utilizes dual-branch cross-attention mechanisms to guide cross-modal interactions, facilitating the encoding of semantic embeddings.
            Concurrently, the visual-artifact localization module gathers local spatial information to establish artifact embeddings through supervised localization.
          </p>
          <p>
            Subsequently, the encoded knowledge representation embeddings are mapped to the language space of LVLMs with projectors.
            We devise MFND instruction-following data for fine-tuning and employ both candidate answer heuristics and soft prompts to unleash the extensive knowledge of language models.
          </p>

        </div>
      </div>
    </div>
    <!--/ Method. -->

    <!-- Experiment. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experiments</h2>
      </div>
    </div>
    <!--/ Experiment. -->
  </div>
</section>


<!-- Experiment1. -->
<div class="container is-max-desktop">
<div class="hero-body">
  <img src="./static/images/single_domain_performance.png" alt="Teaser Image" height="100%">
  <h2 class="subtitle has-text-centered">
    Single-domain performance (%) comparison of baseline models on DGM<sup>4</sup> dataset.
  </h2>
</div>
</div>

<!--/ Experiment2-->
<div class="container is-max-desktop">
<div class="hero-body">
  <img src="./static/images/multiple_domain_performance.png" alt="Teaser Image" height="100%">
  <h2 class="subtitle has-text-centered">
    Multiple-domain performance (%) comparison of baseline models on DGM<sup>4</sup> dataset.
  </h2>
</div>
</div>

<!-- Reference. -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{liu2024fka,
  title={FKA-Owl: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs},
  author={Liu, Xuannan and Li, Peipei and Huang, Huaibo and Li, Zekun and Cui, Xing and Liang, Jiahao and Qin, Lixiong and Deng, Weihong and He, Zhaofeng},
  booktitle={ACM MM},
  year={2024}
}</code></pre>
  </div>
</section>
<!--/ Reference. -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2403.01988">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/liuxuannan/FAK-Owl" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
<script>
  $(document).ready(function(){
    $('.your-carousel').slick({
      slidesToShow: 1,
      slidesToScroll: 1,
      infinite: true,
      dots: true,
      arrows: true,
      autoplay: true,
      autoplaySpeed: 4000,
    });
  });
</script>

<script>
  $(document).ready(function(){
    $('.your-carousel-video').slick({
      slidesToShow: 1,
      slidesToScroll: 1,
      infinite: true,
      dots: true,
      arrows: true,
      autoplay: false, // Turn off slick's autoplay, we will handle it manually
    });

    // Function to play the current video
    function playCurrentVideo() {
      var currentVideo = $('.your-carousel-video .slick-current').find('video').get(0);
      if (currentVideo) {
        currentVideo.play();
        currentVideo.onended = function() {
          $('.your-carousel-video').slick('slickNext');
        };
      }
    }
        // Play the first video explicitly
    setTimeout(function() {
      playCurrentVideo();
    }, 500); // Slight delay to ensure everything is loaded
    //
    // // Initialize the first video
    // // playCurrentVideo();
    // // $('.your-carousel-video').on('init', function(event, slick){
    // //   playCurrentVideo();
    // // });
    //
    // // When the slide changes, play the new video
    // $('.your-carousel-video').on('afterChange', function(event, slick, currentSlide){
    //   playCurrentVideo();
    //       // Trigger slick initialization
    // $('.your-carousel-video').slick('setPosition');
    // });
    // When the carousel is initialized, play the first video
    $('.your-carousel').on('init', function(event, slick){
      playCurrentVideo();
    });

    // When the slide changes, play the new video
    $('.your-carousel').on('afterChange', function(event, slick, currentSlide){
      playCurrentVideo();
    });

    // Trigger slick initialization
    $('.your-carousel').slick('setPosition');

    // Play the first video explicitly
    // playCurrentVideo();


  });
</script>

</body>
</html>